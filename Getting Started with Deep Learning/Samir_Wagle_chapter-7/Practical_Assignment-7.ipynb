{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVrDVX9r_Hxc"
      },
      "source": [
        "## Learning Text Representations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nS3BSBzeCTQ8"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "C4ODhfPf_LSE"
      },
      "outputs": [],
      "source": [
        "def softmax(u):\n",
        "    exp_u = np.exp(u - np.max(u))  # For numerical stability\n",
        "    return exp_u / np.sum(exp_u)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-P263WcuCU08"
      },
      "outputs": [],
      "source": [
        "def Single_context_CBOW(x, label, W1, W2, lr, loss):\n",
        "\n",
        "    # Forward propagation\n",
        "    h = np.dot(W1.T, x)\n",
        "    u = np.dot(W2.T, h)\n",
        "    y_pred = softmax(u)\n",
        "\n",
        "    # error\n",
        "    e = -label + y_pred\n",
        "\n",
        "    # Backward propagation\n",
        "    dW2 = np.outer(h, e)\n",
        "    dW1 = np.outer(x, np.dot(W2, e))\n",
        "\n",
        "    # Update weights\n",
        "    W1 = W1 - lr * dW1\n",
        "    W2 = W2 - lr * dW2\n",
        "\n",
        "    # Loss function\n",
        "    loss += -float(u[label == 1]) + np.log(np.sum(np.exp(u)))\n",
        "\n",
        "    return W1, W2, loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgcxY5lVCtTi",
        "outputId": "105f2ee0-b504-452d-942b-70d9653d2654"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated W1:\n",
            " [[0.84088415 0.45568162 0.32715687 0.97967392]\n",
            " [0.56972814 0.03161001 0.65794655 0.35959826]\n",
            " [0.14239547 0.95862406 0.61828065 0.45492024]\n",
            " [0.9858003  0.44781334 0.02205796 0.4643884 ]\n",
            " [0.1564013  0.33227212 0.81369239 0.43698621]\n",
            " [0.28473761 0.87718824 0.32072009 0.32393398]]\n",
            "Updated W2:\n",
            " [[0.44801547 0.25285078 0.24883883 0.1433884  0.25427217 0.12103724]\n",
            " [0.63404782 0.42656877 0.27490643 0.87256287 0.21310852 0.46287194]\n",
            " [0.12216394 0.21627667 0.32798213 0.08692437 0.76880657 0.50842412]\n",
            " [0.69652933 0.29758073 0.62016249 0.05484967 0.73324612 0.43147069]]\n",
            "Loss: 1.801166559747447\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\L E G I O N\\AppData\\Local\\Temp\\ipykernel_25552\\570312566.py:20: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  loss += -float(u[label == 1]) + np.log(np.sum(np.exp(u)))\n"
          ]
        }
      ],
      "source": [
        "# Example\n",
        "# Vocabulary size and embedding dimensions\n",
        "vocab_size = 6\n",
        "embedding_dim = 4\n",
        "\n",
        "# Initialize random one-hot encoded input and label\n",
        "x = np.zeros((vocab_size, 1))\n",
        "x[2] = 1  # Example input word index\n",
        "\n",
        "label = np.zeros((vocab_size, 1))\n",
        "label[3] = 1  # Example target word index\n",
        "\n",
        "# Initialize weight matrices and learning rate\n",
        "W1 = np.random.rand(vocab_size, embedding_dim)\n",
        "W2 = np.random.rand(embedding_dim, vocab_size)\n",
        "lr = 0.01\n",
        "loss = 0\n",
        "\n",
        "# Training\n",
        "W1, W2, loss = Single_context_CBOW(x, label, W1, W2, lr, loss)\n",
        "\n",
        "print(\"Updated W1:\\n\", W1)\n",
        "print(\"Updated W2:\\n\", W2)\n",
        "print(\"Loss:\", loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snlw1oSdFdxW"
      },
      "source": [
        "**Building the word2vec model using gensim**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmqjcDiqEfuS",
        "outputId": "06e6a593-3172-4e13-bb1d-50e18e595ac7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to C:\\Users\\L E G I O\n",
            "[nltk_data]     N\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "import nltk\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Data processing\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stopWords = stopwords.words('english')\n",
        "\n",
        "# Modeling\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import Phrases\n",
        "from gensim.models.phrases import Phraser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUg0UhW9K6Xe"
      },
      "source": [
        "**Loading the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zWlfD1SUKSCN"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('text.csv',header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WHpnESa0K1TK",
        "outputId": "1a64107e-9f5a-4630-9f44-bdbfc303de61"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>room kind clean strong smell dogs. generally a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>stayed crown plaza april april . staff friendl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>booked hotel hotwire lowest price could find. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>stayed husband sons way alaska cruise. loved h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>girlfriends stayed celebrate th birthdays. pla...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0\n",
              "0  room kind clean strong smell dogs. generally a...\n",
              "1  stayed crown plaza april april . staff friendl...\n",
              "2  booked hotel hotwire lowest price could find. ...\n",
              "3  stayed husband sons way alaska cruise. loved h...\n",
              "4  girlfriends stayed celebrate th birthdays. pla..."
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9brbomhLAGL"
      },
      "source": [
        "**Preprocessing and preparing the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xB9zzAH_K5eZ"
      },
      "outputs": [],
      "source": [
        "def pre_process(text):\n",
        "\n",
        "    #convert to lowercase\n",
        "    text = str(text).lower()\n",
        "\n",
        "    #remove all special characters and keep only alpha numeric characters and spaces\n",
        "    text = re.sub(r'[^A-Za-z0-9\\s.]',r'',text)\n",
        "\n",
        "    #remove new lines\n",
        "    text = re.sub(r'\\n',r' ',text)\n",
        "\n",
        "    # remove stop words\n",
        "    text = \" \".join([word for word in text.split() if word not in stopWords])\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "lKmdDnVILIda",
        "outputId": "75ea1ed1-e3cc-470a-86b6-e3e426f081e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'agree fancy. everything needed. breakfast pool hot tub nice shuttle airport later checkout time. noise issue tough sleep through. awhile forget noisy door nearby noisy guests. complained management later email credit compd us amount requested would return.'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pre_process(data[0][50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QnRetqT1LNfe"
      },
      "outputs": [],
      "source": [
        "data[0] = data[0].map(lambda x: pre_process(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoK_Mr4dLRlf",
        "outputId": "2bde277c-7206-4d11-b636-fad554b5d640"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['stayed crown plaza april april ',\n",
              " ' staff friendly attentive',\n",
              " ' elevators tiny ',\n",
              " ' food restaurant delicious priced little high side',\n",
              " ' course washington dc']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[0][1].split(\".\")[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7N52jps1LWOs"
      },
      "outputs": [],
      "source": [
        "corpus = []\n",
        "for line in data[0][1].split('.'):\n",
        "    words = [x for x in line.split()]\n",
        "    corpus.append(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfL_tNsJLfF2",
        "outputId": "e98ecd8e-1a4d-49a1-b37b-6154cbffa7a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['stayed', 'crown', 'plaza', 'april', 'april'],\n",
              " ['staff', 'friendly', 'attentive']]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ILh7zQcLiOD",
        "outputId": "8509faef-fd8b-4608-9f57-c2fda9da6b77"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['room', 'kind', 'clean', 'strong', 'smell', 'dogs'],\n",
              " ['generally', 'average', 'ok', 'overnight', 'stay', 'youre', 'fussy']]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = data[0].map(lambda x: x.split('.'))\n",
        "\n",
        "corpus = []\n",
        "for i in (range(len(data))):\n",
        "    for line in data[i]:\n",
        "        words = [x for x in line.split()]\n",
        "        corpus.append(words)\n",
        "\n",
        "corpus[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WQamrp-LLkXv"
      },
      "outputs": [],
      "source": [
        "phrases = Phrases(sentences=corpus,min_count=25,threshold=50)\n",
        "bigram = Phraser(phrases)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCv7X_AjLpWm",
        "outputId": "e80523f4-f112-4f87-b417-f7011fe4c37e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['wonderful',\n",
              " 'staff',\n",
              " 'great',\n",
              " 'location',\n",
              " 'definately',\n",
              " 'price',\n",
              " 'high',\n",
              " 'standard',\n",
              " 'hotel']"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus[100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ug-K6LiOLsIt",
        "outputId": "e9436e42-a6f7-491c-a39d-c9f258bebd16"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['course', 'washington', 'dc']"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus[9]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKsNsWf1LyG2"
      },
      "source": [
        "## Building the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "6ddgoe-nLvNE"
      },
      "outputs": [],
      "source": [
        "size = 100\n",
        "window_size = 2\n",
        "epochs = 100\n",
        "min_count = 2\n",
        "workers = 4\n",
        "sg = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "OvrbE5gPL2p1"
      },
      "outputs": [],
      "source": [
        "model = Word2Vec(corpus, sg=1, window=window_size, vector_size=size, min_count=min_count, workers=workers, epochs=epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "F4Nca9QDL4yu"
      },
      "outputs": [],
      "source": [
        "model.save('word2vec.model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "L3VYdI8bL8c9"
      },
      "outputs": [],
      "source": [
        "model = Word2Vec.load('word2vec.model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRwd3ysUR05q"
      },
      "source": [
        "## Evaluating the embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1uy4YdfSZfr",
        "outputId": "616fd181-dc77-489d-a45a-41189e403698"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n",
            "False\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "print('san_diego' in model.wv.key_to_index)\n",
        "print('san diego' in model.wv.key_to_index)\n",
        "print('San_Diego' in model.wv.key_to_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Urx2DVohL99F",
        "outputId": "8dd20b95-3a07-4bb1-8da6-cd5a8add9dd6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('diego', 0.6002644896507263),\n",
              " ('san', 0.5842916369438171),\n",
              " ('coastline', 0.5682160258293152),\n",
              " ('carless', 0.5434173941612244),\n",
              " ('field', 0.5417526364326477),\n",
              " ('locationeasy', 0.5396423935890198),\n",
              " ('sausilito', 0.5394237041473389),\n",
              " ('mustsee', 0.5366553068161011),\n",
              " ('dallas', 0.5347569584846497),\n",
              " ('haightashbury', 0.5316208600997925)]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.wv.most_similar('sandiego')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmsS3ZTvR2u0",
        "outputId": "e9719fb4-495c-4f60-c75e-098d210916e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('queen', 0.6996593475341797)]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.wv.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "6gaZGP5OS7cr",
        "outputId": "2039453f-ec9a-4bd3-8a74-154a010283fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'holiday'"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = ['los_angeles','indianapolis', 'holiday', 'san_antonio','new_york']\n",
        "\n",
        "model.wv.doesnt_match(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hqXJUV-TNsA"
      },
      "source": [
        "## Visualizing word embeddings in TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "tJa2g7AsTBbk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\L E G I O N\\AppData\\Local\\Temp\\ipykernel_25552\\866649310.py:6: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "tf.compat.v1.reset_default_graph()\n",
        "from tensorboard.plugins import projector\n",
        "import numpy as np\n",
        "import gensim\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "cYma9W0-TYvM"
      },
      "outputs": [],
      "source": [
        "max_size = len(model.wv.index_to_key) - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "tUI3W-s9TerX"
      },
      "outputs": [],
      "source": [
        "w2v = np.zeros((max_size, model.vector_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "3TiaNSjqTof2"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('projections'):\n",
        "    os.makedirs('projections')\n",
        "\n",
        "with open(\"projections/metadata.tsv\", 'w+') as file_metadata:\n",
        "\n",
        "    for i, word in enumerate(model.wv.index_to_key[:max_size]):\n",
        "\n",
        "        # store the embeddings of the word\n",
        "        w2v[i] = model.wv[word]\n",
        "\n",
        "        # write the word to a file\n",
        "        file_metadata.write(word + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "VmxpszorTxiS"
      },
      "outputs": [],
      "source": [
        "sess = tf.compat.v1.InteractiveSession()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "8Qoo-kiGUEND"
      },
      "outputs": [],
      "source": [
        "with tf.device(\"/cpu:0\"):\n",
        "    embedding = tf.Variable(w2v, trainable=False, name='embedding')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "CMZclY9rUGhO"
      },
      "outputs": [],
      "source": [
        "tf.compat.v1.global_variables_initializer().run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "RgsSrNj5UXEJ"
      },
      "outputs": [],
      "source": [
        "saver = tf.compat.v1.train.Saver()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "0v8mdVj4UmCL"
      },
      "outputs": [],
      "source": [
        "writer = tf.compat.v1.summary.FileWriter('projections', sess.graph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "NjBv43wDUnAB"
      },
      "outputs": [],
      "source": [
        "config = projector.ProjectorConfig()\n",
        "embed= config.embeddings.add()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "XzqAcwcdUown"
      },
      "outputs": [],
      "source": [
        "embed.tensor_name = 'embedding'\n",
        "embed.metadata_path = 'metadata.tsv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "hOmyIYi5Urta",
        "outputId": "34f5a2fc-840d-40d5-cfc7-83eb107b00d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'projections/model.ckpt-27330'"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "projector.visualize_embeddings(writer, config)\n",
        "\n",
        "saver.save(sess, 'projections/model.ckpt', global_step=max_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dhfBsJZU7ab"
      },
      "source": [
        "## Finding similar documents using doc2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "eI39QejZUt_z"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import os\n",
        "import gensim\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "\n",
        "from nltk import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "stopWords = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "MQTl8XRhnD3N"
      },
      "outputs": [],
      "source": [
        "docLabels = []\n",
        "docLabels = [f for f in os.listdir('news_dataset') if  f.endswith('.txt')]\n",
        "\n",
        "data = []\n",
        "for doc in docLabels:\n",
        "    data.append(open('news_dataset/'+doc, encoding='utf-8', errors='ignore').read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNCESwk0Vv6Z",
        "outputId": "3959121a-00f5-49b1-b697-368853747776"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Electronics_0.txt',\n",
              " 'Electronics_1.txt',\n",
              " 'Electronics_10.txt',\n",
              " 'Electronics_100.txt',\n",
              " 'Electronics_101.txt']"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docLabels[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "ThX7hF32WtvY"
      },
      "outputs": [],
      "source": [
        "class DocIterator(object):\n",
        "    def __init__(self, doc_list, labels_list):\n",
        "        self.labels_list = labels_list\n",
        "        self.doc_list = doc_list\n",
        "\n",
        "    def __iter__(self):\n",
        "        for idx, doc in enumerate(self.doc_list):\n",
        "            yield TaggedDocument(words=doc.split(), tags=[self.labels_list[idx]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "SGwPIEoVWvYC"
      },
      "outputs": [],
      "source": [
        "it = DocIterator(data, docLabels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "5muvJYQDWwth"
      },
      "outputs": [],
      "source": [
        "size = 100\n",
        "alpha = 0.025\n",
        "min_alpha = 0.025\n",
        "dm = 1\n",
        "min_count = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "1LIVEEi6WyH5"
      },
      "outputs": [],
      "source": [
        "model = gensim.models.Doc2Vec(vector_size=size, min_count=min_count, alpha=alpha, min_alpha=min_alpha, dm=dm)\n",
        "model.build_vocab(it)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "SK9J1UzYW0Z5"
      },
      "outputs": [],
      "source": [
        "for epoch in range(100):\n",
        "    model.train(it, total_examples=model.corpus_count, epochs=1)\n",
        "    model.alpha -= 0.002\n",
        "    model.min_alpha = model.alpha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "Brd8ePDLW2Jj"
      },
      "outputs": [],
      "source": [
        "model.save('doc2vec.model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "nusgnWnkW8DJ"
      },
      "outputs": [],
      "source": [
        "d2v_model = gensim.models.doc2vec.Doc2Vec.load('doc2vec.model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrCoiEsKW9jI",
        "outputId": "e6fc2880-bc65-43c8-c57a-fca6c5f2760b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('Sports_381.txt', 0.8735464811325073),\n",
              " ('Science_344.txt', 0.8635656833648682),\n",
              " ('Sports_635.txt', 0.8628700375556946),\n",
              " ('Science_722.txt', 0.8572390079498291),\n",
              " ('Science_366.txt', 0.8502411842346191),\n",
              " ('Politics_872.txt', 0.8497423529624939),\n",
              " ('Politics_578.txt', 0.8470869064331055),\n",
              " ('Science_725.txt', 0.8466042280197144),\n",
              " ('Politics_476.txt', 0.8451502919197083),\n",
              " ('Electronics_463.txt', 0.8404396176338196)]"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.docvecs.most_similar('Electronics_666.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMBFBk9koejO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
